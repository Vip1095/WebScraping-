{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas\n",
    "import math\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "import csv\n",
    "import random\n",
    "import math\n",
    "import operator\n",
    "from sklearn.preprocessing import MinMaxScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getAccuracy(testSet, predictions):\n",
    "        correct = 0\n",
    "        for x in range(len(testSet)):\n",
    "                if testSet[x] == predictions[x]:\n",
    "                        correct += 1\n",
    "        return (correct/float(len(testSet))) * 100.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def backPropagation():\n",
    "    # fix random seed for reproducibility\n",
    "    seed=7\n",
    "    numpy.random.seed(seed)\n",
    "\n",
    "    trainingSet=[]\n",
    "    testSet=[]\n",
    "\n",
    "    data = numpy.loadtxt(\"E://Student.csv\", delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>READING</th>\n",
       "      <th>ANNOTATION</th>\n",
       "      <th>BACKTRACKING</th>\n",
       "      <th>UNDERLINE</th>\n",
       "      <th>KNOWLEDGE LEVEL</th>\n",
       "      <th>PERFORMANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JIIT-128</td>\n",
       "      <td>B</td>\n",
       "      <td>22</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>60.0</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>JIIT-128</td>\n",
       "      <td>G</td>\n",
       "      <td>19</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>34.0</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>JIIT-128</td>\n",
       "      <td>B</td>\n",
       "      <td>20</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>56.0</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>JIIT-128</td>\n",
       "      <td>G</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>76.0</td>\n",
       "      <td>LOW</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>JIIT-62</td>\n",
       "      <td>G</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>GOOD</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Student SEX  AGE  READING  ANNOTATION  BACKTRACKING  UNDERLINE  \\\n",
       "0  JIIT-128   B   22        1           1             4          4   \n",
       "1  JIIT-128   G   19        3           5             2          2   \n",
       "2  JIIT-128   B   20        4           4             4          3   \n",
       "3  JIIT-128   G   23        4           7             7          2   \n",
       "4   JIIT-62   G   22        2           8             3          2   \n",
       "\n",
       "   KNOWLEDGE LEVEL PERFORMANCE  \n",
       "0             60.0        GOOD  \n",
       "1             34.0         LOW  \n",
       "2             56.0        GOOD  \n",
       "3             76.0         LOW  \n",
       "4             67.0        GOOD  "
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.io.parsers.read_csv(\"E://Student.csv\")\n",
    "header=None,\n",
    "usecols=[0,1,2,3,4,5,6,7,8]\n",
    "df.columns=['Student','SEX','AGE','READING', 'ANNOTATION','BACKTRACKING','UNDERLINE','KNOWLEDGE LEVEL','PERFORMANCE']\n",
    "df.head()\n",
    "                            \n",
    "                            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anacon\\lib\\site-packages\\ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "F:\\anacon\\lib\\site-packages\\ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "F:\\anacon\\lib\\site-packages\\ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "data['Student'] = data['Student'].apply(lambda x: 1 if x == 'JIIT-128' else 0)\n",
    "data['SEX'] = data['SEX'].apply(lambda x: 1 if x == 'B' else 0)\n",
    "data[\"PERFORMANCE\"][data[\"PERFORMANCE\"] == \"LOW\"] = 0\n",
    "data[\"PERFORMANCE\"][data[\"PERFORMANCE\"] == \"MEDIUM\"] = 1\n",
    "data[\"PERFORMANCE\"][data[\"PERFORMANCE\"] == \"GOOD\"] = 2\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Student</th>\n",
       "      <th>SEX</th>\n",
       "      <th>AGE</th>\n",
       "      <th>READING</th>\n",
       "      <th>ANNOTATION</th>\n",
       "      <th>BACKTRACKING</th>\n",
       "      <th>UNDERLINE</th>\n",
       "      <th>KNOWLEDGE LEVEL</th>\n",
       "      <th>PERFORMANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>201</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>406</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>5</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>72</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>384</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>337</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>107</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>2</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>138</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>430</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>394</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>15</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>98.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>483</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>364</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>54.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>428</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>410</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>458</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>362</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>34</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>363</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>65.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>372</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>358</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>449</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>49.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>8</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>98.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>213</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>4</td>\n",
       "      <td>76.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>235</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>8</td>\n",
       "      <td>9</td>\n",
       "      <td>8</td>\n",
       "      <td>3</td>\n",
       "      <td>78.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>334</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>348</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>399</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>471</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "      <td>45.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>360</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>89.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>267</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>422</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>5</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>67.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>25</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>56.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>391</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>271</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>24</td>\n",
       "      <td>5</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>43.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>74.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>145</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>7</td>\n",
       "      <td>9</td>\n",
       "      <td>7</td>\n",
       "      <td>3</td>\n",
       "      <td>23.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>23</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>5</td>\n",
       "      <td>5</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>279</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>21</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>404</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>19</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>503 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Student  SEX  AGE  READING  ANNOTATION  BACKTRACKING  UNDERLINE  \\\n",
       "172        0    0   21        3           7             5          1   \n",
       "78         0    0   24        2           4             2          1   \n",
       "201        0    0   25        2           9             4          1   \n",
       "406        0    0   19        6           9             6          5   \n",
       "72         0    0   23        2           9             9          1   \n",
       "384        0    0   21        5           4             7          3   \n",
       "337        0    0   21        6           8             6          4   \n",
       "107        0    0   23        4           4             5          4   \n",
       "367        0    0   19        5           9             6          4   \n",
       "200        0    0   25        9           9             8          1   \n",
       "4          0    0   22        2           8             3          2   \n",
       "138        0    0   24        2           3             8          3   \n",
       "225        0    0   25        5           9             6          4   \n",
       "430        0    0   21        5           9             4          4   \n",
       "394        0    0   24        7           4             8          3   \n",
       "5          0    0   15        3           3             1          3   \n",
       "483        0    0   25        6           9             1          3   \n",
       "92         0    0   21        4           9             6          1   \n",
       "62         0    0   21        8           9             8          1   \n",
       "364        0    0   19        6           4             1          4   \n",
       "111        0    0   25        9           9             7          1   \n",
       "6          0    0   21        1           9             1          3   \n",
       "428        0    0   21        8           9             3          3   \n",
       "179        0    0   21        6           4             4          5   \n",
       "410        0    0   21        4           4             5          3   \n",
       "458        0    0   24        8           9             7          3   \n",
       "362        0    0   21        8           3             9          1   \n",
       "322        0    0   23        5           4             5          1   \n",
       "496        0    0   34        9           6             6          3   \n",
       "363        0    0   21        6           3             1          4   \n",
       "..       ...  ...  ...      ...         ...           ...        ...   \n",
       "372        0    0   21        9           9             4          5   \n",
       "358        0    0   21        9           2             9          3   \n",
       "89         0    0   23        6           2             1          4   \n",
       "449        0    0   25        8           3             6          4   \n",
       "9          0    0   22        3           4             7          3   \n",
       "191        0    0   23        8           7             6          1   \n",
       "309        0    0   21        2           9             1          3   \n",
       "303        0    0   21        4           9             8          5   \n",
       "213        0    0   19        5           9             5          4   \n",
       "235        0    0   24        8           9             8          3   \n",
       "334        0    0   21        4           9             3          3   \n",
       "348        0    0   21        8           5             5          1   \n",
       "399        0    0   21        8           5             5          5   \n",
       "471        0    0   23        4           6             7          2   \n",
       "360        0    0   21        8           2             7          3   \n",
       "41         0    0   21        7           6             3          5   \n",
       "267        0    0   21        2           9             1          4   \n",
       "422        0    0   21        4           9             1          2   \n",
       "222        0    0   25        5           5             8          5   \n",
       "51         0    0   23        2           9             2          5   \n",
       "344        0    0   21        7           5             1          4   \n",
       "154        0    0   25        2           4             6          4   \n",
       "391        0    0   21        7           9             5          2   \n",
       "271        0    0   19        8           6             7          3   \n",
       "192        0    0   24        5           7             4          4   \n",
       "23         0    0   22        4           5             9          1   \n",
       "145        0    0   21        7           9             7          3   \n",
       "66         0    0   23        2           9             5          5   \n",
       "279        0    0   21        5           9             1          3   \n",
       "404        0    0   19        9           9             1          5   \n",
       "\n",
       "     KNOWLEDGE LEVEL PERFORMANCE  \n",
       "172             87.0           0  \n",
       "78              89.0           0  \n",
       "201             56.0           1  \n",
       "406             76.0           2  \n",
       "72              89.0           2  \n",
       "384             87.0           0  \n",
       "337             67.0           2  \n",
       "107             87.0           0  \n",
       "367             56.0           0  \n",
       "200             87.0           1  \n",
       "4               67.0           2  \n",
       "138             45.0           0  \n",
       "225             87.0           0  \n",
       "430             45.0           1  \n",
       "394             87.0           0  \n",
       "5               98.0           1  \n",
       "483             87.0           0  \n",
       "92              87.0           0  \n",
       "62              89.0           1  \n",
       "364             87.0           0  \n",
       "111              5.0           0  \n",
       "6               54.0           1  \n",
       "428             87.0           1  \n",
       "179             87.0           0  \n",
       "410             87.0           0  \n",
       "458             87.0           2  \n",
       "362             87.0           0  \n",
       "322             87.0           0  \n",
       "496             34.0           2  \n",
       "363             65.0           0  \n",
       "..               ...         ...  \n",
       "372             87.0           0  \n",
       "358              8.0           0  \n",
       "89              67.0           0  \n",
       "449             87.0           0  \n",
       "9               49.0           2  \n",
       "191             87.0           2  \n",
       "309             56.0           0  \n",
       "303             98.0           0  \n",
       "213             76.0           1  \n",
       "235             78.0           0  \n",
       "334             44.0           1  \n",
       "348              8.0           0  \n",
       "399             87.0           0  \n",
       "471             45.0           0  \n",
       "360             67.0           2  \n",
       "41              89.0           1  \n",
       "267             45.0           1  \n",
       "422             87.0           0  \n",
       "222              3.0           0  \n",
       "51              56.0           2  \n",
       "344             67.0           2  \n",
       "154             56.0           0  \n",
       "391             87.0           0  \n",
       "271             87.0           2  \n",
       "192             43.0           1  \n",
       "23              74.0           2  \n",
       "145             23.0           1  \n",
       "66              56.0           1  \n",
       "279             87.0           0  \n",
       "404             87.0           0  \n",
       "\n",
       "[503 rows x 9 columns]"
      ]
     },
     "execution_count": 170,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.sample(n=503)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>READING</th>\n",
       "      <th>ANNOTATION</th>\n",
       "      <th>BACKTRACKING</th>\n",
       "      <th>UNDERLINE</th>\n",
       "      <th>KNOWLEDGE LEVEL</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>374</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.250</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.885417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>0.555556</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>421</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.885417</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>365</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.562500</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>238</th>\n",
       "      <td>0.777778</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.885417</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      READING  ANNOTATION  BACKTRACKING  UNDERLINE  KNOWLEDGE LEVEL\n",
       "374  1.000000       1.000         0.250       1.00         0.885417\n",
       "367  0.555556       1.000         0.625       0.75         0.562500\n",
       "421  0.444444       1.000         1.000       0.25         0.885417\n",
       "365  0.666667       0.375         0.750       0.75         0.562500\n",
       "238  0.777778       0.375         0.750       0.00         0.885417"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_norm = data[['READING','ANNOTATION','BACKTRACKING','UNDERLINE', 'KNOWLEDGE LEVEL']].apply(lambda x: (x - x.min()) / (x.max() - x.min()))\n",
    "df_norm.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PERFORMANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>442</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70</th>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>149</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>359</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>283</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     PERFORMANCE\n",
       "442            1\n",
       "70             2\n",
       "149            0\n",
       "359            0\n",
       "283            0"
      ]
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = data[['PERFORMANCE']].replace(['LOW','MEDIUM','GOOD'],[0,1,2])\n",
    "target.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>READING</th>\n",
       "      <th>ANNOTATION</th>\n",
       "      <th>BACKTRACKING</th>\n",
       "      <th>UNDERLINE</th>\n",
       "      <th>KNOWLEDGE LEVEL</th>\n",
       "      <th>PERFORMANCE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.875</td>\n",
       "      <td>1.00</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.625</td>\n",
       "      <td>0.000</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>123</th>\n",
       "      <td>0.666667</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.906250</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>0.444444</td>\n",
       "      <td>0.375</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.885417</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>432</th>\n",
       "      <td>0.222222</td>\n",
       "      <td>1.000</td>\n",
       "      <td>0.500</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.468750</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      READING  ANNOTATION  BACKTRACKING  UNDERLINE  KNOWLEDGE LEVEL  \\\n",
       "303  0.444444       1.000         0.875       1.00         1.000000   \n",
       "258  1.000000       0.625         0.000       1.00         0.906250   \n",
       "123  0.666667       1.000         0.000       0.00         0.906250   \n",
       "102  0.444444       0.375         0.500       0.25         0.885417   \n",
       "432  0.222222       1.000         0.500       1.00         0.468750   \n",
       "\n",
       "     PERFORMANCE  \n",
       "303            0  \n",
       "258            0  \n",
       "123            0  \n",
       "102            2  \n",
       "432            1  "
      ]
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.concat([df_norm, target], axis=1)\n",
    "df.sample(n=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "X = df.values[:,1:]\n",
    "y = df.values[:,0]\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
    "    test_size=0.30, random_state=12345)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating Neural Network...\n"
     ]
    }
   ],
   "source": [
    " print('Creating Neural Network...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anacon\\lib\\site-packages\\ipykernel_launcher.py:3: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(5, input_dim=5, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n",
      "F:\\anacon\\lib\\site-packages\\ipykernel_launcher.py:4: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(4, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  after removing the cwd from sys.path.\n",
      "F:\\anacon\\lib\\site-packages\\ipykernel_launcher.py:5: UserWarning: Update your `Dense` call to the Keras 2 API: `Dense(1, activation=\"sigmoid\", kernel_initializer=\"uniform\")`\n",
      "  \"\"\"\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model=Sequential()\n",
    "model.add(Dense(5, input_dim=5, init='uniform', activation='sigmoid'))\n",
    "model.add(Dense(4, init='uniform', activation='sigmoid'))\n",
    "model.add(Dense(1, init='uniform', activation='sigmoid'))\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training the model...\n"
     ]
    }
   ],
   "source": [
    "print('Training the model...')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile model\n",
    "from keras.utils import to_categorical\n",
    "y_binary = to_categorical(y)\n",
    "\n",
    "model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "F:\\anacon\\lib\\site-packages\\keras\\models.py:942: UserWarning: The `nb_epoch` argument in `fit` has been renamed `epochs`.\n",
      "  warnings.warn('The `nb_epoch` argument in `fit` '\n"
     ]
    },
    {
     "ename": "InvalidArgumentError",
     "evalue": "Received a label value of 1 which is outside the valid range of [0, 1).  Label values: 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n\t [[Node: loss_11/dense_29_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _class=[\"loc:@train...s_grad/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](loss_11/dense_29_loss/Log, loss_11/dense_29_loss/Cast)]]\n\nCaused by op 'loss_11/dense_29_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits', defined at:\n  File \"F:\\anacon\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"F:\\anacon\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"F:\\anacon\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"F:\\anacon\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"F:\\anacon\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"F:\\anacon\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\anacon\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"F:\\anacon\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"F:\\anacon\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"F:\\anacon\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"F:\\anacon\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"F:\\anacon\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"F:\\anacon\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-157-64a7af8d7c5f>\", line 5, in <module>\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n  File \"F:\\anacon\\lib\\site-packages\\keras\\models.py\", line 824, in compile\n    **kwargs)\n  File \"F:\\anacon\\lib\\site-packages\\keras\\engine\\training.py\", line 830, in compile\n    sample_weight, mask)\n  File \"F:\\anacon\\lib\\site-packages\\keras\\engine\\training.py\", line 429, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"F:\\anacon\\lib\\site-packages\\keras\\losses.py\", line 73, in sparse_categorical_crossentropy\n    return K.sparse_categorical_crossentropy(y_true, y_pred)\n  File \"F:\\anacon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3041, in sparse_categorical_crossentropy\n    logits=logits)\n  File \"F:\\anacon\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2050, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"F:\\anacon\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 8018, in sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"F:\\anacon\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"F:\\anacon\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"F:\\anacon\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Received a label value of 1 which is outside the valid range of [0, 1).  Label values: 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n\t [[Node: loss_11/dense_29_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _class=[\"loc:@train...s_grad/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](loss_11/dense_29_loss/Log, loss_11/dense_29_loss/Cast)]]\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32mF:\\anacon\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1321\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1322\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1323\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacon\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[1;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[0;32m   1306\u001b[0m       return self._call_tf_sessionrun(\n\u001b[1;32m-> 1307\u001b[1;33m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[0;32m   1308\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacon\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[1;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[0;32m   1408\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1409\u001b[1;33m           run_metadata)\n\u001b[0m\u001b[0;32m   1410\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Received a label value of 1 which is outside the valid range of [0, 1).  Label values: 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n\t [[Node: loss_11/dense_29_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _class=[\"loc:@train...s_grad/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](loss_11/dense_29_loss/Log, loss_11/dense_29_loss/Cast)]]",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m                      Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-158-c92a1b8802c5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# Fit the model\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 2\u001b[1;33m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnb_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m15\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32mF:\\anacon\\lib\\site-packages\\keras\\models.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m    961\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    962\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 963\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m    964\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    965\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mF:\\anacon\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[0;32m   1703\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1704\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1705\u001b[1;33m                               validation_steps=validation_steps)\n\u001b[0m\u001b[0;32m   1706\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1707\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[1;32mF:\\anacon\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[1;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[0;32m   1233\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1234\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1235\u001b[1;33m                     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mf\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1236\u001b[0m                     \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1237\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, inputs)\u001b[0m\n\u001b[0;32m   2476\u001b[0m         \u001b[0msession\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2477\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[1;32m-> 2478\u001b[1;33m                               **self.session_kwargs)\n\u001b[0m\u001b[0;32m   2479\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacon\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m    898\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    899\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[1;32m--> 900\u001b[1;33m                          run_metadata_ptr)\n\u001b[0m\u001b[0;32m    901\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    902\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacon\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_run\u001b[1;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1133\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[1;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[1;32mor\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1134\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[1;32m-> 1135\u001b[1;33m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[0;32m   1136\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1137\u001b[0m       \u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacon\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_run\u001b[1;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[0;32m   1314\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1315\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[1;32m-> 1316\u001b[1;33m                            run_metadata)\n\u001b[0m\u001b[0;32m   1317\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1318\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mF:\\anacon\\lib\\site-packages\\tensorflow\\python\\client\\session.py\u001b[0m in \u001b[0;36m_do_call\u001b[1;34m(self, fn, *args)\u001b[0m\n\u001b[0;32m   1333\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1334\u001b[0m           \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1335\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0mtype\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnode_def\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mop\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1337\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_extend_graph\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mInvalidArgumentError\u001b[0m: Received a label value of 1 which is outside the valid range of [0, 1).  Label values: 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n\t [[Node: loss_11/dense_29_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _class=[\"loc:@train...s_grad/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](loss_11/dense_29_loss/Log, loss_11/dense_29_loss/Cast)]]\n\nCaused by op 'loss_11/dense_29_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits', defined at:\n  File \"F:\\anacon\\lib\\runpy.py\", line 193, in _run_module_as_main\n    \"__main__\", mod_spec)\n  File \"F:\\anacon\\lib\\runpy.py\", line 85, in _run_code\n    exec(code, run_globals)\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel_launcher.py\", line 16, in <module>\n    app.launch_new_instance()\n  File \"F:\\anacon\\lib\\site-packages\\traitlets\\config\\application.py\", line 658, in launch_instance\n    app.start()\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel\\kernelapp.py\", line 478, in start\n    self.io_loop.start()\n  File \"F:\\anacon\\lib\\site-packages\\zmq\\eventloop\\ioloop.py\", line 177, in start\n    super(ZMQIOLoop, self).start()\n  File \"F:\\anacon\\lib\\site-packages\\tornado\\ioloop.py\", line 888, in start\n    handler_func(fd_obj, events)\n  File \"F:\\anacon\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\anacon\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 440, in _handle_events\n    self._handle_recv()\n  File \"F:\\anacon\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 472, in _handle_recv\n    self._run_callback(callback, msg)\n  File \"F:\\anacon\\lib\\site-packages\\zmq\\eventloop\\zmqstream.py\", line 414, in _run_callback\n    callback(*args, **kwargs)\n  File \"F:\\anacon\\lib\\site-packages\\tornado\\stack_context.py\", line 277, in null_wrapper\n    return fn(*args, **kwargs)\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 283, in dispatcher\n    return self.dispatch_shell(stream, msg)\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 233, in dispatch_shell\n    handler(stream, idents, msg)\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel\\kernelbase.py\", line 399, in execute_request\n    user_expressions, allow_stdin)\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel\\ipkernel.py\", line 208, in do_execute\n    res = shell.run_cell(code, store_history=store_history, silent=silent)\n  File \"F:\\anacon\\lib\\site-packages\\ipykernel\\zmqshell.py\", line 537, in run_cell\n    return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n  File \"F:\\anacon\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2728, in run_cell\n    interactivity=interactivity, compiler=compiler, result=result)\n  File \"F:\\anacon\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2856, in run_ast_nodes\n    if self.run_code(code, result):\n  File \"F:\\anacon\\lib\\site-packages\\IPython\\core\\interactiveshell.py\", line 2910, in run_code\n    exec(code_obj, self.user_global_ns, self.user_ns)\n  File \"<ipython-input-157-64a7af8d7c5f>\", line 5, in <module>\n    model.compile(loss='sparse_categorical_crossentropy', optimizer='adam')\n  File \"F:\\anacon\\lib\\site-packages\\keras\\models.py\", line 824, in compile\n    **kwargs)\n  File \"F:\\anacon\\lib\\site-packages\\keras\\engine\\training.py\", line 830, in compile\n    sample_weight, mask)\n  File \"F:\\anacon\\lib\\site-packages\\keras\\engine\\training.py\", line 429, in weighted\n    score_array = fn(y_true, y_pred)\n  File \"F:\\anacon\\lib\\site-packages\\keras\\losses.py\", line 73, in sparse_categorical_crossentropy\n    return K.sparse_categorical_crossentropy(y_true, y_pred)\n  File \"F:\\anacon\\lib\\site-packages\\keras\\backend\\tensorflow_backend.py\", line 3041, in sparse_categorical_crossentropy\n    logits=logits)\n  File \"F:\\anacon\\lib\\site-packages\\tensorflow\\python\\ops\\nn_ops.py\", line 2050, in sparse_softmax_cross_entropy_with_logits\n    precise_logits, labels, name=name)\n  File \"F:\\anacon\\lib\\site-packages\\tensorflow\\python\\ops\\gen_nn_ops.py\", line 8018, in sparse_softmax_cross_entropy_with_logits\n    labels=labels, name=name)\n  File \"F:\\anacon\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py\", line 787, in _apply_op_helper\n    op_def=op_def)\n  File \"F:\\anacon\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 3392, in create_op\n    op_def=op_def)\n  File \"F:\\anacon\\lib\\site-packages\\tensorflow\\python\\framework\\ops.py\", line 1718, in __init__\n    self._traceback = self._graph._extract_stack()  # pylint: disable=protected-access\n\nInvalidArgumentError (see above for traceback): Received a label value of 1 which is outside the valid range of [0, 1).  Label values: 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0\n\t [[Node: loss_11/dense_29_loss/SparseSoftmaxCrossEntropyWithLogits/SparseSoftmaxCrossEntropyWithLogits = SparseSoftmaxCrossEntropyWithLogits[T=DT_FLOAT, Tlabels=DT_INT64, _class=[\"loc:@train...s_grad/mul\"], _device=\"/job:localhost/replica:0/task:0/device:CPU:0\"](loss_11/dense_29_loss/Log, loss_11/dense_29_loss/Cast)]]\n"
     ]
    }
   ],
   "source": [
    "# Fit the model\n",
    "model.fit(X_train, y_train, nb_epoch=300, batch_size=15,verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "1  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "2  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "3  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "4  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "5  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "6  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "7  predicted=1.0, actual=1.0\n",
      "Accuracy: 5.298013%\n",
      "8  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "9  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n",
      "10  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "11  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "12  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "13  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "14  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n",
      "15  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "16  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "17  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "18  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n",
      "19  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n",
      "20  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "21  predicted=1.0, actual=1.0\n",
      "Accuracy: 5.298013%\n",
      "22  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "23  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "24  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "25  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "26  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "27  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "28  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "29  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "30  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "31  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "32  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "33  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "34  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "35  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "36  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "37  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "38  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n",
      "39  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "40  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "41  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "42  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "43  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "44  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "45  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "46  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n",
      "47  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "48  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "49  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "50  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "51  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "52  predicted=1.0, actual=0.1111111111111111\n",
      "Accuracy: 5.298013%\n",
      "53  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "54  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "55  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "56  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "57  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "58  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "59  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "60  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "61  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "62  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "63  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "64  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "65  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "66  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "67  predicted=1.0, actual=1.0\n",
      "Accuracy: 5.298013%\n",
      "68  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n",
      "69  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "70  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "71  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "72  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "73  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "74  predicted=1.0, actual=1.0\n",
      "Accuracy: 5.298013%\n",
      "75  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "76  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "77  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "78  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "79  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "80  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "81  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "82  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "83  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "84  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "85  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n",
      "86  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "87  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "88  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "89  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "90  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "91  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "92  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "93  predicted=1.0, actual=1.0\n",
      "Accuracy: 5.298013%\n",
      "94  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "95  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "96  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "97  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "98  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "99  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "100  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "101  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "102  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "103  predicted=1.0, actual=1.0\n",
      "Accuracy: 5.298013%\n",
      "104  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n",
      "105  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "106  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "107  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "108  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "109  predicted=1.0, actual=1.0\n",
      "Accuracy: 5.298013%\n",
      "110  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "111  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n",
      "112  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "113  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "114  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "115  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "116  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n",
      "117  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "118  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 5.298013%\n",
      "119  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "120  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "121  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "122  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "123  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "124  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "125  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "126  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "127  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "128  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "129  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "130  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "131  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 5.298013%\n",
      "132  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "133  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "134  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n",
      "135  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "136  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "137  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "138  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "139  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "140  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "141  predicted=1.0, actual=0.1111111111111111\n",
      "Accuracy: 5.298013%\n",
      "142  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "143  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "144  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 5.298013%\n",
      "145  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "146  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 5.298013%\n",
      "147  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 5.298013%\n",
      "148  predicted=1.0, actual=1.0\n",
      "Accuracy: 5.298013%\n",
      "149  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 5.298013%\n",
      "150  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 5.298013%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-165-073d1cbd8ce0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %.6f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtestScore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mbackPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-115-18e71fa40349>\u001b[0m in \u001b[0;36mbackPropagation\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# fix random seed for reproducibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrainingSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "for i in range(len(y_test)):\n",
    "    print(str(i)+'  predicted='+str(rounded[i])+', actual='+ str(y_test[i]))\n",
    "    testScore=getAccuracy(y_test,rounded)\n",
    "    print(\"Accuracy: %.6f%%\" % (testScore))\n",
    "\n",
    "backPropagation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "1  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "2  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "3  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "4  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "5  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "6  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "7  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "8  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "9  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "10  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "11  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "12  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "13  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "14  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "15  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "16  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "17  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "18  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "19  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "20  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "21  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "22  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "23  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "24  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "25  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "26  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "27  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "28  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "29  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "30  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "31  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "32  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "33  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "34  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "35  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "36  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "37  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "38  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "39  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "40  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "41  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "42  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "43  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "44  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "45  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "46  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "47  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "48  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "49  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "50  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "51  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "52  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "53  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "54  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "55  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "56  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "57  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "58  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "59  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "60  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "61  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "62  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "63  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "64  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "65  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "66  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "67  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "68  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "69  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "70  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "71  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "72  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "73  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "74  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "75  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "76  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "77  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "78  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "79  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "80  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "81  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "82  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "83  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "84  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "85  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "86  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "87  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "88  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "89  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "90  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "91  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "92  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "93  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "94  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "95  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "96  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "97  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "98  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "99  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "100  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "101  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "102  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "103  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "104  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "105  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "106  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "107  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "108  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "109  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "110  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "111  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "112  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "113  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "114  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "115  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "116  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "117  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "118  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "119  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "120  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "121  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "122  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "123  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "124  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "125  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "126  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "127  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "128  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "129  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "130  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "131  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "132  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "133  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "134  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "135  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "136  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "137  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "138  predicted=nan, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "139  predicted=1.0, actual=0.1111111111111111\n",
      "Accuracy: 9.375000%\n",
      "140  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "141  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "142  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "143  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "144  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "145  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "146  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "147  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "148  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "149  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "150  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "151  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "152  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "153  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "154  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "155  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "156  predicted=1.0, actual=0.1111111111111111\n",
      "Accuracy: 9.375000%\n",
      "157  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "158  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "159  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "160  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "161  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "162  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "163  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "164  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "165  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "166  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "167  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "168  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "169  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "170  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "171  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "172  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "173  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "174  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "175  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "176  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "177  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "178  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "179  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "180  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "181  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "182  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "183  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "184  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "185  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "186  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "187  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "188  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "189  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "190  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "191  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "192  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "193  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "194  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "195  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "196  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "197  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "198  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "199  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "200  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "201  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "202  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "203  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "204  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "205  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "206  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "207  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "208  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "209  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "210  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "211  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "212  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "213  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "214  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "215  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "216  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "217  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "218  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "219  predicted=1.0, actual=0.1111111111111111\n",
      "Accuracy: 9.375000%\n",
      "220  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "221  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "222  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "223  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "224  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "225  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "226  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "227  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "228  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "229  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "230  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "231  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "232  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "233  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "234  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "235  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "236  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "237  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "238  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "239  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "240  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "241  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "242  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "243  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "244  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "245  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "246  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "247  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "248  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "249  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "250  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "251  predicted=1.0, actual=0.1111111111111111\n",
      "Accuracy: 9.375000%\n",
      "252  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "253  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "254  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "255  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "256  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "257  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "258  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "259  predicted=1.0, actual=0.1111111111111111\n",
      "Accuracy: 9.375000%\n",
      "260  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "261  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "262  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "263  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "264  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "265  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "266  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "267  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "268  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "269  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "270  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "271  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "272  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "273  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "274  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "275  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "276  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "277  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "278  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "279  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "280  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "281  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "282  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "283  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "284  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "285  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "286  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "287  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "288  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "289  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "290  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "291  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "292  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "293  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "294  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "295  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "296  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "297  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "298  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "299  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "300  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "301  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "302  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "303  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "304  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "305  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "306  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "307  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "308  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "309  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "310  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "311  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "312  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "313  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "314  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "315  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "316  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "317  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "318  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "319  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "320  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "321  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "322  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "323  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "324  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "325  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "326  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "327  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "328  predicted=1.0, actual=0.0\n",
      "Accuracy: 9.375000%\n",
      "329  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "330  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "331  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "332  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "333  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "334  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "335  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "336  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "337  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "338  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "339  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "340  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "341  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "342  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "343  predicted=1.0, actual=0.4444444444444444\n",
      "Accuracy: 9.375000%\n",
      "344  predicted=1.0, actual=1.0\n",
      "Accuracy: 9.375000%\n",
      "345  predicted=1.0, actual=0.5555555555555556\n",
      "Accuracy: 9.375000%\n",
      "346  predicted=1.0, actual=0.8888888888888888\n",
      "Accuracy: 9.375000%\n",
      "347  predicted=1.0, actual=0.3333333333333333\n",
      "Accuracy: 9.375000%\n",
      "348  predicted=1.0, actual=0.6666666666666666\n",
      "Accuracy: 9.375000%\n",
      "349  predicted=1.0, actual=0.7777777777777778\n",
      "Accuracy: 9.375000%\n",
      "350  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n",
      "351  predicted=1.0, actual=0.2222222222222222\n",
      "Accuracy: 9.375000%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'numpy' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-167-79321d2157f5>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Accuracy: %.6f%%\"\u001b[0m \u001b[1;33m%\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mtestScore\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mbackPropagation\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-115-18e71fa40349>\u001b[0m in \u001b[0;36mbackPropagation\u001b[1;34m()\u001b[0m\n\u001b[0;32m      2\u001b[0m     \u001b[1;31m# fix random seed for reproducibility\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mseed\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m7\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mnumpy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mtrainingSet\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'numpy' is not defined"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "rounded = [round(x[0]) for x in predictions]\n",
    "for i in range(len(y_train)):\n",
    "    print(str(i)+'  predicted='+str(rounded[i])+', actual='+ str(y_train[i]))\n",
    "    testScore=getAccuracy(y_train,rounded)\n",
    "    print(\"Accuracy: %.6f%%\" % (testScore))\n",
    "\n",
    "backPropagation()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
